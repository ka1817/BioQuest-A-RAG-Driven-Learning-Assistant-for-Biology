{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c8d1cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ef7bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader \n",
    "from langchain.document_loaders import PyPDFLoader \n",
    "data_folder = \"../data\"  \n",
    "\n",
    "loader = DirectoryLoader(data_folder, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f3f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter \n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5772a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6281b774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\AppData\\Local\\Temp\\ipykernel_28688\\3920331017.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\saipr\\BioRag\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4114f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS \n",
    "vectorstore=FAISS.from_documents(chunks,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bba4b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq \n",
    "import os \n",
    "GROQ_API_KEY=os.getenv('GROQ_API_KEY')\n",
    "\n",
    "llm=ChatGroq(api_key=GROQ_API_KEY,model='llama-3.3-70b-versatile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "888fdff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever_dense = vectorstore.as_retriever(search_kwargs={\"k\": 10})  \n",
    "bm25_retriever = BM25Retriever.from_documents(chunks)\n",
    "\n",
    "hybrid_retriever = EnsembleRetriever(retrievers=[retriever_dense, bm25_retriever], weights=[0.5, 0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0fc1fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful and knowledgeable biology tutor. Answer clearly and accurately.if the query is out of sylabus just give Out of syllabus\"),\n",
    "    (\"human\", \"Context:\\n{context}\\n\\nQuestion: {question}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46892e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\AppData\\Local\\Temp\\ipykernel_28688\\1796011903.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=3\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93709061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saipr\\AppData\\Local\\Temp\\ipykernel_28688\\253123294.py:36: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"question\": query})\n",
      "C:\\Users\\saipr\\AppData\\Local\\Temp\\ipykernel_28688\\253123294.py:20: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  initial_docs = self.base_retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To prove that carbon dioxide is necessary for photosynthesis, two chemicals required are:\n",
      "\n",
      "1. Potassium hydroxide (KOH) - to absorb carbon dioxide\n",
      "2. Iodine - to test the presence of starch in the leaves.\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain.schema import Document, BaseRetriever \n",
    "from sentence_transformers import CrossEncoder\n",
    "from pydantic import BaseModel  \n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
    "\n",
    "def rerank_documents(query: str, retrieved_docs: List[Document]) -> List[Document]:\n",
    "    docs_texts = [doc.page_content for doc in retrieved_docs]\n",
    "    pairs = [(query, doc_text) for doc_text in docs_texts]\n",
    "    scores = reranker.predict(pairs)\n",
    "    sorted_docs = [doc for _, doc in sorted(zip(scores, retrieved_docs), key=lambda x: x[0], reverse=True)]\n",
    "    return sorted_docs\n",
    "\n",
    "class RerankRetriever(BaseRetriever, BaseModel): \n",
    "    base_retriever: BaseRetriever  \n",
    "    top_k: int = 5  \n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        initial_docs = self.base_retriever.get_relevant_documents(query)\n",
    "        reranked_docs = rerank_documents(query, initial_docs)\n",
    "        return reranked_docs[:self.top_k]  \n",
    "\n",
    "base_retriever = EnsembleRetriever(retrievers=[retriever_dense, bm25_retriever], weights=[0.5, 0.5])\n",
    "\n",
    "\n",
    "custom_retriever = RerankRetriever(base_retriever=base_retriever, top_k=5)\n",
    "\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=custom_retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": prompt}\n",
    ")\n",
    "query=\"Write two chemical required to conduct an experiment to prove that carbon dioxide is necessary for photosynthesis\"\n",
    "result = qa_chain({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88bacc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['chat_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4980be1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859c6fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
